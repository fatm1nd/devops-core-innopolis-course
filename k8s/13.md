# Persistense memory

```bash
fatm1nd@fatm1nd-IdeaPad-5-14ARE05:~/Documents/Innopolis/devops-core-innopolis-course$ kubectl get po,sts,svc,pvc
NAME                       READY   STATUS    RESTARTS      AGE
pod/devops-lab-web-app-0   1/1     Running   1 (46s ago)   27h
pod/devops-lab-web-app-1   1/1     Running   1 (46s ago)   27h

NAME                                  READY   AGE
statefulset.apps/devops-lab-web-app   2/2     27h

NAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/devops-lab-web-app   ClusterIP   10.111.87.229   <none>        5000/TCP   27h
service/kubernetes           ClusterIP   10.96.0.1       <none>        443/TCP    31d

NAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/data-devops-lab-web-app-0   Bound    pvc-e6b82a30-7514-4381-bc60-b634882c9d2b   1Gi        RWO            standard       27h
persistentvolumeclaim/data-devops-lab-web-app-1   Bound    pvc-50c87e9a-c1d3-47b9-bc22-0ca65e67ea28   1Gi        RWO            standard       27h
fatm1nd@fatm1nd-IdeaPad-5-14ARE05:~$ kubectl exec pod/devops-lab-web-app-1 -- cat /home/lab_user/app/data/visits.txt
20
fatm1nd@fatm1nd-IdeaPad-5-14ARE05:~$ kubectl exec pod/devops-lab-web-app-0 -- cat /home/lab_user/app/data/visits.txt
14
```

The initial pod garnered a higher number of visits compared to the second pod, likely due to the fact that `minikube service` primarily directed requests to the first pod, while the second pod mainly received healthcheck requests. If there had been load balancing in place, the visit counts might have been more evenly distributed.

## Lack of Ordering Guarantees
Ordering guarantees are unnecessary for my application since each pod operates independently of the others. Consequently, we can commence multiple pods simultaneously without concern for sequential ordering.